#############################################
## Pre-Training Tutorial Train Data Config ##
#############################################

setup:
    data:
        type: "huggingface"
        source: "karpathy/tiny_shakespeare"
        split: "train"
    mode: "pretraining"
    output_dir: "pretraining_tutorial/train_data"
    processes: 1

processing:
    huggingface_tokenizer: "baseten/Meta-Llama-3-tokenizer"
    write_in_batch: True
    read_hook: "cerebras.modelzoo.data_preparation.data_preprocessing.hooks:text_read_hook"
    read_hook_kwargs:
        data_keys:
            text_key: "text"

dataset:
    use_ftfy: True